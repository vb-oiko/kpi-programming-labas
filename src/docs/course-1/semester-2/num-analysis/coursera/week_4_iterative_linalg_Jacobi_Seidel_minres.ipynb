{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
       "        1.11022302e-16,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "       -2.77555756e-17,  1.11022302e-16])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.03919429  0.03780037  0.04283232  0.02365951  0.05745031 -0.00030244\n -0.00577279  0.03177549 -0.00422849  0.05284648]\n0.38959181027260875 2.005305120107153e-17\n0.4185783948614869 1.6502682545529e-17\n0.4522284025473819 3.622208959480119e-17\n0.4917667095178099 2.72080745804227e-17\n0.5388887887486234 2.660694867584809e-17\n0.5960110344093966 1.0255972154762448e-15\n0.6667001660296402 2.770910834768342e-13\n0.7564517359241753 1.4990529163071287e-10\n0.8742017351588476 2.0161596093475135e-07\n1.0355299928250665 0.0009191717405677889\n1.2702850939751231 23.48163367953916\n1.6439565658213244 8260242.793633645\n2.334809111760855 261149802433164.78\n4.080768845910033 1.3716691464130671e+26\n30.715327603064885 1.739863582849129e+61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Jacobi_iteration(A, b, eps=1e-7, n_iter=50):\n",
    "\n",
    "    diag_1d = np.diag(A)\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    invD = np.diag(1./diag_1d)\n",
    "    BB = invD @ B\n",
    "    c = invD @ b\n",
    "\n",
    "    x = np.ones(n)\n",
    "    for _ in range(n_iter):\n",
    "        x = BB @ x + c\n",
    "    return x\n",
    "\n",
    "\n",
    "x = Jacobi_iteration(A, b)\n",
    "print(x)\n",
    "\n",
    "np.testing.assert_allclose(A@x, b)\n",
    "np.testing.assert_allclose(x, xx)\n",
    "\n",
    "for k in range(1, 16):\n",
    "    A1 = A + np.diagflat([-k]*n)\n",
    "    print(np.linalg.norm(np.diag(1./np.diag(A1))@(-A1.copy()+np.diag(np.diag(A1)))),\n",
    "          np.linalg.norm(Jacobi_iteration(A1, b)-np.linalg.solve(A1, b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.38959181027260875 1.5540063044689707e-17\n0.4185783948614869 2.303412968156487e-17\n0.4522284025473819 3.3107778123195866e-17\n0.4917667095178099 1.717836144195444e-17\n0.5388887887486234 1.8703665918870363e-17\n0.5960110344093966 2.6208106743381504e-17\n0.6667001660296402 3.222105849667643e-17\n0.7564517359241753 3.894444544739273e-17\n0.8742017351588476 4.3610271956070115e-17\n1.0355299928250665 7.521581756278068e-17\n1.2702850939751231 6.691626947686432e-17\n1.6439565658213244 1.0829177162645093e-16\n2.334809111760855 1.1775693440128312e-16\n4.080768845910033 4.10633611443092e-09\n30.715327603064885 2.224327617064848e+114\n"
     ]
    }
   ],
   "source": [
    "def seidel_iteration(A, b, eps=1e-7, n_iter=50):\n",
    "    x = np.ones(b.shape[0])\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        for k in range(b.shape[0]):\n",
    "            x[k] = (b[k]-np.dot(A[k][:k], x[:k]) -\n",
    "                    np.dot(A[k][k+1:], x[k+1:]))/A[k, k]\n",
    "    return x\n",
    "\n",
    "\n",
    "x = seidel_iteration(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@x, b)\n",
    "np.testing.assert_allclose(x, xx)\n",
    "\n",
    "for k in range(1, 16):\n",
    "    A1 = A + np.diagflat([-k]*n)\n",
    "    print(np.linalg.norm(np.diag(1./np.diag(A1))@(-A1.copy()+np.diag(np.diag(A1)))),\n",
    "          np.linalg.norm(seidel_iteration(A1, b)-np.linalg.solve(A1, b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.38959181027260875 2.224174099750403e-17\n",
      "0.4185783948614869 2.32747678105055e-17\n",
      "0.4522284025473819 3.867305227724097e-17\n",
      "0.4917667095178099 2.823925224926892e-17\n",
      "0.5388887887486234 1.717288626685379e-17\n",
      "0.5960110344093966 2.3338317471424865e-17\n",
      "0.6667001660296402 3.309641454705087e-17\n",
      "0.7564517359241753 nan\n",
      "0.8742017351588476 4.718958039861916e-17\n",
      "1.0355299928250665 7.11870997173569e-17\n",
      "1.2702850939751231 6.834017936133213e-17\n",
      "1.6439565658213244 1.0367784962136927e-16\n",
      "2.334809111760855 1.0822660244255038e-13\n",
      "4.080768845910033 0.00021717913683793173\n",
      "30.715327603064885 2.0818042350846104\n",
      "<ipython-input-34-15f69d125d4b>:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  k = (r @ A @ r)/np.linalg.norm(A @ r)**2\n"
     ]
    }
   ],
   "source": [
    "def minimum_res_scheme(A, b, eps=1e-7, n_iter=50):\n",
    "    x = np.ones(b.shape[0])\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        r = A @ x - b\n",
    "        k = (r @ A @ r)/np.linalg.norm(A @ r)**2\n",
    "        x = x - k*r\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "x = minimum_res_scheme(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@x, b)\n",
    "np.testing.assert_allclose(x, xx)\n",
    "\n",
    "for k in range(1, 16):\n",
    "    A1 = A + np.diagflat([-k]*n)\n",
    "    print(np.linalg.norm(np.diag(1./np.diag(A1))@(-A1.copy()+np.diag(np.diag(A1)))),\n",
    "          np.linalg.norm(minimum_res_scheme(A1, b)-np.linalg.solve(A1, b)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}